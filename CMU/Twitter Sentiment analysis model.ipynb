{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readConHandles():\n",
    "    prueba=pd.read_csv('everything.csv')\n",
    "    labels=prueba[['Label']].convert_objects(convert_numeric=True)\n",
    "    data=prueba[['Tweet']]\n",
    "    handles=prueba[['Handle']]\n",
    "    labelsList=labels['Label'].fillna(0).values.tolist()\n",
    "    dataList=prueba['Tweet'].values.tolist()\n",
    "    lista=prueba['Handle'].values.tolist()\n",
    "    nueva=[]\n",
    "    for i in range(len(lista)):\n",
    "        nueva.append(lista[i]+' '+dataList[i])\n",
    "    return nueva, labelsList\n",
    "    #esto hace que los handles sean la primera \"palabra\" del string para la bag of words para que sean tomados en cuenta \n",
    "    #(esto va a hacer todo mil mas larga y no se si vaya a valer la pena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read():\n",
    "    prueba=pd.read_csv('everythingEVEN.csv')\n",
    "    labels=prueba[['Label']].convert_objects(convert_numeric=True)\n",
    "    data=prueba[['Tweet']]\n",
    "    handles=prueba[['Handle']]\n",
    "    labelsList=labels['Label'].fillna(0).values.tolist()\n",
    "    dataList=prueba['Tweet'].values.tolist()\n",
    "    lista=prueba['Handle'].values.tolist()\n",
    "    return dataList, labelsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "dataList, labelsList=readConHandles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 2, 52, 0, 28, 108)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erroresTodos(expectedL[1],predictedL[1]) #01 02 10 12 20 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english',min_df=1)\n",
    "X = vectorizer.fit_transform(dataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2),stop_words='english',\n",
    "                                     token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "X2=vectorizer.fit_transform(dataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, trainLabels, testLabels = train_test_split(X.toarray(), labelsList, test_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='poly')\n",
    "clf.fit(X_train, trainLabels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svmPred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821565044027\n",
      "[[   0    0  447]\n",
      " [   0    0  627]\n",
      " [   0    0 4945]]\n"
     ]
    }
   ],
   "source": [
    "expected = testLabels\n",
    "print(metrics.accuracy_score(expected, svmPred))\n",
    "print(metrics.confusion_matrix(expected, svmPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.893836185413\n",
      "[[ 253   42  152]\n",
      " [  51  300  276]\n",
      " [  26   92 4827]]\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=1,\n",
    "     random_state=0)\n",
    "#scores = cross_val_score(clf, X, y)\n",
    "clf.fit(X_train, trainLabels) \n",
    "predicted = clf.predict(X_test)\n",
    "print(metrics.accuracy_score(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "     min_samples_split=1, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=1,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, trainLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.891177936534\n",
      "[[ 199   16  232]\n",
      " [  24  248  355]\n",
      " [   3   25 4917]]\n"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None,\n",
    "     min_samples_split=1, random_state=0)\n",
    "clf.fit(X_train, trainLabels)\n",
    "predicted = clf.predict(X_test)\n",
    "print(metrics.accuracy_score(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expectedL=[]\n",
    "predictedL=[]\n",
    "scoreL=[]\n",
    "conf=np.zeros((3, 3))\n",
    "for i in range(10+1):\n",
    "    X_train, X_test, trainLabels, testLabels = train_test_split(X.toarray(), labelsList, test_size=0.75)\n",
    "    #model=MultinomialNB()\n",
    "    #model.fit(X_train, trainLabels)\n",
    "    expected = testLabels\n",
    "    #predicted = model.predict(X_test)\n",
    "    #clf = DecisionTreeClassifier(max_depth=None, min_samples_split=1)\n",
    "    #clf = RandomForestClassifier(n_estimators=10, max_depth=None,min_samples_split=1)\n",
    "    clf = DecisionTreeClassifier(max_depth=None, min_samples_split=1)\n",
    "    clf.fit(X_train, trainLabels) \n",
    "    predicted = clf.predict(X_test)\n",
    "    expectedL.append(expected)\n",
    "    predictedL.append(predicted)\n",
    "    scoreL.append(metrics.accuracy_score(expected, predicted))\n",
    "    conf+=metrics.confusion_matrix(expected, predicted)\n",
    "    #print(metrics.accuracy_score(expected, predicted))\n",
    "    #print(metrics.classification_report(expected, predicted))\n",
    "    #print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89750638130767724"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scoreL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  307.3,    53.6,   106.8],\n",
       "       [   77.7,   347.5,   252.9],\n",
       "       [   59.5,   128.1,  5287.5]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline=[random.randint(0,2) for i in range(len(predicted))]\n",
    "print(metrics.accuracy_score(expected, baseline))\n",
    "print(metrics.confusion_matrix(expected, baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
